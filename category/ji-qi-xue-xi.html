<!doctype html>
<html class="no-js" lang="en">
	<head>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1.0" />

		<title>Newerly's Blog</title>
		<meta name="description" content="">
		<meta name="author" content="Patrick">

		<link rel="stylesheet" href="/theme/css/foundation.css" />
        <link rel="stylesheet" href="/theme/tipuesearch/tipuesearch.css">
		<link rel="stylesheet" href="/theme/css/pygment/monokai.css" />
		<link rel="stylesheet" href="/theme/css/custom.css" />


		<script src="/theme/js/modernizr.js"></script>

		<!-- Feeds -->


		<!-- mathjax config similar to math.stackexchange -->
		<script type="text/x-mathjax-config">
		MathJax.Hub.Config({
			jax: ["input/TeX", "output/HTML-CSS"],
			tex2jax: {
				inlineMath: [ ['$', '$'] ],
				displayMath: [ ['$$', '$$']],
				processEscapes: true,
				skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
			},
			messageStyle: "none",
			"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
		});
		</script>
		<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
	</head>
	<body>
		<div class="off-canvas-wrap">
			<div class="inner-wrap">
				<!-- mobile top bar to activate nav -->
				<nav class="tab-bar show-for-small">
					<section class="left-small">
						<a class="left-off-canvas-toggle menu-icon" ><span></span></a>
					</section>

					<section class="middle tab-bar-section">
						<h1 class="title">Newerly's&nbsp;Blog</h1>
					</section>
				</nav>

				<!-- mobile side bar nav -->
				<aside class="left-off-canvas-menu">
					<ul class="off-canvas-list">
						<li><a href="">Home</a></li>
						<li><label>Categories</label></li>
							<li ><a href="/category/du-shu-bi-ji.html">读书笔记</a></li>
							<li class="active"><a href="/category/ji-qi-xue-xi.html">机器学习</a></li>
							<li ><a href="/category/mongodb.html">Mongodb</a></li>
							<li ><a href="/category/ruan-jian.html">软件</a></li>
							<li ><a href="/category/shu-ju-fen-xi.html">数据分析</a></li>
							<li ><a href="/category/yue-du-bi-ji.html">阅读笔记</a></li>
							<li ><a href="/category/za-xiang.html">杂项</a></li>

                        <form id="searchform" action="/search" onsubmit="return (this.elements['q'].value.length > 0)">
                                <input id="searchbox" type="text" name="q" size="12" placeholder="Search">
                            </form>
						<li><label>Links</label></li>
							<li><a href="http://getpelican.com/">Pelican</a></li>
							<li><a href="http://python.org/">Python.org</a></li>
							<li><a href="http://jinja.pocoo.org/">Jinja2</a></li>



						<li><label>Social</label></li>
					</ul>	
				</aside>

				<!-- top bar nav -->
				<nav class="top-bar hide-for-small-only" data-topbar>
					<ul class="title-area">
						<li class="name">
							<h1><a href="/">Newerly's Blog</a></h1>
						</li>
					</ul>

					<section class="top-bar-section">
						<ul class="left">
								<li ><a href="/category/du-shu-bi-ji.html">读书笔记</a></li>
								<li class="active"><a href="/category/ji-qi-xue-xi.html">机器学习</a></li>
								<li ><a href="/category/mongodb.html">Mongodb</a></li>
								<li ><a href="/category/ruan-jian.html">软件</a></li>
								<li ><a href="/category/shu-ju-fen-xi.html">数据分析</a></li>
								<li ><a href="/category/yue-du-bi-ji.html">阅读笔记</a></li>
								<li ><a href="/category/za-xiang.html">杂项</a></li>
						</ul>
                        <ul class="right">                                                                                                                                           
                                                                                                          
····                                                                                                                                       
                                     <li><a href="/pages/about.html">About</a></li>                                    
                                                                                                                                          
                                                                                                                                             
                        </ul>  
					</section>
				</nav>

				<!-- Main Page Content and Sidebar -->
				<section class="main-section">
					<div class="row">
						<!-- Main Content -->
						<div class="medium-9 small-12 columns" role="content">
							<div class="row">
								<div class="small-12 columns">
									<h2>Category: 机器学习</h2>
								</div>
							</div>

<article>
	<h3><a href="/ju-lei-mo-hu-ju-lei-ji-qi-you-xiao-xing.html">聚类，模糊聚类及其有效性</a></h3>
	<h6>Written by <a href="/author/patrick.html">Patrick</a> in <a href="/category/ji-qi-xue-xi.html">机器学习</a> on 三 14 十月 2015.</h6>
	<h4><strong> 1. 聚类问题 </strong></h4>
<p>如果我们把聚类问题描述为在一堆数据中寻找一种“自然分组”，那么我们就必须定义“自然分组”的含义。从什么意义上，我们能够说同一类中的样本比来自不同类的样本更为相似？这个问题实际上涉及两个独立的子问题：</p>
<ul>
<li><strong>怎样度量样本之间的相似性？</strong></li>
<li><strong>怎样衡量对样本集的一种划分的好坏？</strong></li>
</ul>
<h5><strong> 1) 相似性度量 </strong></h5>
<p>一种直观的做法是将样本集映射或定义到一个度量空间中，通过距离来衡量样本之间的相似性，常用的欧几里德距离便是其一，样本集在欧几里德空间中进行度量。但这个广泛使用的度量方法存在以下需要注意的问题：</p>
<ul>
<li>
<p>如果特征空间是各向同性的并且数据大致均匀分布在各个方向上，使用欧几里德距离是合理的。<strong>但对高维稀疏、各向不均衡的数据，这种度量方式就会存在问题</strong>。</p>
</li>
<li>
<p>规范化是实现不变性的一种方法。选用欧几里德距离得到的聚类结果将不会因特征空间的平移和旋转而改变，所以数据点作刚体运动不会影响分类结果。但一般地说，对线性变换或其他会扭曲距离关系的变换是不能保证的。要实现位移和缩放的不变性，可以通过平移和缩放坐标轴使新样本集具有零均值和单位方差；要实现旋转不变性，可以旋转坐标轴使这些轴与样本协方差矩阵的特征向量平行，即主成分变换。</p>
</li>
<li>
<p>但不能说规范化一定是必要的。通过平移和缩放使得均值为0,方差为1的规范化方法，其出发点是有效防止某些特征仅仅因为它的数值过大而主导(dominate)距离度量。对于服从正态波动的数据进行规范化操作是合理的，但如果数据的波动是因为存在多个子类，那么规范化就不合理了，因为这将改变样本数据类内和类间在原始空间中的分布，影响分类结果的正确性。<strong> 因此，对于聚类算法，一般不对原始样本集进行规范化处理？ </strong></p>
</li>
</ul>
<p>几类常用相似性度量方法：</p>
<ul>
<li><strong>Minkowski度量 ...</strong></li></ul>
		<p class="continue"><a href="/ju-lei-mo-hu-ju-lei-ji-qi-you-xiao-xing.html">Continue reading &raquo;</a></p>
</article>
<hr />
<article>
	<h3><a href="/ju-lei-yan-jiu-sui-bi-1005.html">聚类研究随笔-1005</a></h3>
	<h6>Written by <a href="/author/patrick.html">Patrick</a> in <a href="/category/ji-qi-xue-xi.html">机器学习</a> on 一 05 十月 2015.</h6>
	<h4><strong> 1.聚类有效性问题 </strong></h4>
<p>聚类算法是一种无监督的学习算法，实现对各定数据的结构一无所知，无论用什么算法聚类，其聚类结果的合理性都有待评价。一些算法只能保证收敛到目标函数的局部极值，不用的聚类数和初值就可能得到不同聚类结果，如何评价不同的聚类结果，是聚类有效问题。</p>
<p>Bezdek在1974年提出了聚类有效性函数$V_{pc}(u,c)$，也称为划分系数(Partition Coefficient)，是第一个实用的聚类有效性标准，定义如下：</p>
<p>$$ V_{pc}(u,c)=(1/n)*\sum_{k=1}^{n}\sum_{i=1}^{c}u_{ik}^{2} $$</p>
<p>Bezdek指出可以以上式作为聚类有效性函数，即</p>
<p>$$ \exists{u^<em>,c^</em>}, V_{pc}(u^<em>,c^</em>)=\max_{2\le c ...</p>
		<p class="continue"><a href="/ju-lei-yan-jiu-sui-bi-1005.html">Continue reading &raquo;</a></p>
</article>
<hr />
<article>
	<h3><a href="/pu-ju-lei-yan-yi-mo-xing-yu-dian-xing-suan-fa.html">谱聚类广义模型与典型算法</a></h3>
	<h6>Written by <a href="/author/patrick.html">Patrick</a> in <a href="/category/ji-qi-xue-xi.html">机器学习</a> on 三 30 九月 2015.</h6>
	<p>本文为《谱聚类广义模型与典型算法分析》（《模式识别与人工智能》2014年11月第27卷第11期）的文献阅读笔记。</p>
<blockquote>
<p>谱聚类方法基于点对相似性度量，避免了原型方法的数据凸分布要求，但当图规模较大时，求解特征向量较为困难。此外，谱聚类通过Laplace算子构造数据的非线性低维嵌入，形成可聚类的区域，然而全局的相似性度量易忽略局部差异和多尺度性，在NJW算法、Ncut算法的分割结果中常造成一些局部区域不能分辨的现象，虽然有一些基于局部度量的谱聚类算法，但是他们并没有经过严格的数学论证。</p>
</blockquote>
<p>谱聚类方法使用核函数（可进行非线性映射）计算样本点之间的Gram矩阵（即度量矩阵，将样本从数据空间映射到度量空间中），然后对Gram矩阵进行Laplacian变换（<strong>为什么是拉普拉斯变化</strong>)，计算标准化Laplace矩阵<em>L</em>的特征值和特征向量（<strong>为什么要这么做</strong>）。将索引的特征值降序排列，前若干个最大特征值对应的特征向量构成数据的低维空间，数据在这些特征向量上的投影构成低维嵌入，如下图所示。</p>
<p><img alt="谱聚类过程" src="img/spectral_clustering_process.png" /></p>
<h5><strong> 1.1 谱聚类与核k-means之间的关系 </strong></h5>
<p>k-means的极小化问题可转化为迹最大化问题，核k-means的松弛问题的解可通过核PCA的特征值得到，而通过求解前K个特征值在进行聚类即为谱聚类过程。具体推演过程见Kernel K-means and Spectral Clustering。</p>
<h5><strong> 1.2 谱聚类与权重核k-means </strong></h5>
<p>Dhillon为每个数据点分配一个适当的权重，提出一种权重核k-means算法，并证明其与谱聚类算法的等价性，详见Weighted ...</p>
		<p class="continue"><a href="/pu-ju-lei-yan-yi-mo-xing-yu-dian-xing-suan-fa.html">Continue reading &raquo;</a></p>
</article>
<hr />
<article>
	<h3><a href="/ju-lei-yan-jiu-sui-bi-0929.html">聚类研究随笔-0929</a></h3>
	<h6>Written by <a href="/author/patrick.html">Patrick</a> in <a href="/category/ji-qi-xue-xi.html">机器学习</a> on 二 29 九月 2015.</h6>
	<h5><strong> 现在的问题研究路径是： </strong></h5>
<h5><strong> 1.如何对混杂多种协议的网络数据在类别数未知的条件下进行聚类？ </strong></h5>
<p>目前正在验证<a href="#">USCAWM算法</a>计算最佳聚类数的准确率，USCAWM算法在理论上有严格的证明，在小规模的测试数据集IRIS上验证结果基本正确。但该算法中有两个至关重要的参数，一个是相似度矩阵<em>R(Vi,Vj)</em>，一个是相似性判别阈值，其中<em>R(Vi,Vj)</em>是计算最佳聚类数的关键，当聚类数确定后，各种聚类算法都可做聚类分析，而不一定要像USCAWM算法中那样不断迭代选择最佳阈值。</p>
<p>那么，相似度矩阵的计算实际上涉及的是相似性度量的问题。<em>f: V×V-&gt;R</em>这个相似性度量函数<em>f()</em>将原始的样本空间映射为一个有助于聚类的度量空间，这里要注意两点：</p>
<p>a. 原始样本空间的非线性分布会给采用线性划分的聚类方法带来困难。一般的解决方法是使非线性空间线性化，如采用核函数，或选取能够进行线性划分的维度。所以，从本质上讲，如果能够将样本空间线性化，聚类的难度将大大减小，也就是说，聚类的关键是能够找到一个将样本空间映射为线性度量空间的函数，事实上，这也是很多距离度量定义的初衷。</p>
<p>b. 有助于聚类的度量空间是指，类内紧凑，类间松弛。不论采用线性化映射还是降维选取线性划分的特征 ...</p>
		<p class="continue"><a href="/ju-lei-yan-jiu-sui-bi-0929.html">Continue reading &raquo;</a></p>
</article>
<hr />
<article>
	<h3><a href="/ji-yu-quan-ju-zhen-de-wu-jian-du-pu-ju-lei-suan-fa.html">基于权矩阵的无监督谱聚类算法</a></h3>
	<h6>Written by <a href="/author/patrick.html">Patrick</a> in <a href="/category/ji-qi-xue-xi.html">机器学习</a> on 四 20 八月 2015.</h6>
	<p>USCAWM(unsupervised spectral clustering algorithm based on weight matrix)算法出自《谱聚类的扰动分析》（《中国科学 E辑: 信息科学》2007年第37卷第4期:527~543），该论文以矩阵的扰动理论为工具对谱聚类进行了分析，通过理论证明得到了如下结论：</p>
<ol>
<li>在适当的相似度函数下，聚类的类别数等于权矩阵的特征值中值大于1的特征值的个数;    </li>
<li>在适当的相似度函数下，以权矩阵的前<em>k</em>（聚类的类别数）个单位正交特征向量为列向量组成的行向量之间的夹角可以用来聚类;    </li>
<li>在适当的相似度函数下，大于0的特征值约等于聚类结果中每类的样本个数。  </li>
</ol>
<p>这是一个相当好的结论。在聚类分析中，主要面临的以下三大类问题：</p>
<ol>
<li>已知类别数的条件下，对样本数据集进行聚类，这个是研究的最多，成果也最多的问题;    </li>
<li>未知类别数的条件下，对样本数据集进行最佳聚类，给出聚类性能最优的类别数;</li>
<li>聚类方法是否满足样本数据空间的约束条件，即是否能处理非凸分布，是否能划定非线性的聚类边界;</li>
</ol>
<p>谱聚类方法可以解决第3个问题，能够对任意分布的数据集进行聚类，而USCAWM算法在谱聚类的基础上，在满足一定约束的条件下，解决了第2个问题。但该算法的问题也正在于这个约束条件不稳定、不普适，一些参数的选择也需要技巧和运气，这里就涉及到聚类算法的两个核心问题 ...</p>
		<p class="continue"><a href="/ji-yu-quan-ju-zhen-de-wu-jian-du-pu-ju-lei-suan-fa.html">Continue reading &raquo;</a></p>
</article>
<hr />
<article>
	<h3><a href="/ju-lei-fang-fa-zong-jie.html">聚类方法总结</a></h3>
	<h6>Written by <a href="/author/patrick.html">Patrick</a> in <a href="/category/ji-qi-xue-xi.html">机器学习</a> on 三 19 八月 2015.</h6>
	<p><img alt="聚类方法总结" src="/img/clustering_summary.png" />  <br />
<a href="/img/clustering_summary.png">点击这里看大图</a></p>
		<p class="continue"><a href="/ju-lei-fang-fa-zong-jie.html">Continue reading &raquo;</a></p>
</article>
<hr />


						</div>
						<!-- End Main Content -->
						<!-- Sidebar -->
						<aside class="medium-3 hide-for-small-only columns">
							<div class="panel">
								<h5>Links</h5>
								<ul class="side-nav">
									<li><a href="http://getpelican.com/">Pelican</a></li>
									<li><a href="http://python.org/">Python.org</a></li>
									<li><a href="http://jinja.pocoo.org/">Jinja2</a></li>
								</ul>
							</div>

							<div class="panel">
								<h5>Tags</h5>
								<ul class="tag-cloud">
									<li><a href="/tag/mongodb.html" class="tag-4">mongodb</a></li>
									<li><a href="/tag/机器学习.html" class="tag-4">机器学习</a></li>
									<li><a href="/tag/最近邻.html" class="tag-4">最近邻</a></li>
								</ul>
							</div>


							<div class="panel">
								<h5>Social</h5>
								<ul class="side-nav">
								</ul>
							</div>
						</aside>
						<!-- End Sidebar -->
					</div>

					<!-- Footer -->
					<footer class="row">
						<div class="medium-9 small-12">
							<hr/>
							<p class="text-center">Powered by <a href="http://getpelican.com">Pelican</a> and <a href="http://foundation.zurb.com/">Zurb Foundation</a>. Theme by <a href="http://hamaluik.com">Kenton Hamaluik</a>.</p>
						</div>
					</footer>
					<!-- End Footer -->
				</section>
				<a class="exit-off-canvas"></a>
			</div><!--off-canvas inner-->
		</div><!--off-canvas wrap-->

		<script src="/theme/js/jquery.js"></script>
		<script src="/theme/js/foundation.min.js"></script>
		<script>
			$(document).foundation();
		</script>
	</body>
</html>